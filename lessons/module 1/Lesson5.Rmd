---
title: "Урок пятый: Статистика: нормальное распределение и сравнение групп"
author: "Вячеслав Арбузов"
date: "`r Sys.Date()`"
output: html_document
---

## Распределения

Для работы с распределениями в R имеется следующая конструкция: буква кодирующая действие + название распределения

```{r}
# буквы кодирующие действие:
# d – плотность распределения
# p – распределение функции
# q – квантиль функции
# r – случайные значение 

#название распределений
# norm - нормальное распределение
# unif - равномерное распределение
# t - распределение Стьдента
# exp - экспоненциальное распределение

# примеры использования

# 100 случайный чисел
rnorm(100)

# квантиль уровня 0.5
qnorm(0.5)

# плотность распределения в нуле
dnorm(0)

# функция распределения в нуле
pnorm(0)

# прочие распределения
?rt
?rlnorm
?rexp
?runif
```

## Проверка на нормальность

Рассмотрим разные методы проверки на нормальность начиная от быстрых и не самых надежных (графические) и заканчивая сторого формализованными статистическими тестами. В статистических тестах проверки на нормальность принимаем гипотезу о нормальности выборки, если p-значение больше критического уровня (например 5%)

```{r}
x = rnorm(100)
# Графический – гистограмма
hist(x,freq = F)
# добавим теоретическое стандартное нормальное распределение
curve(dnorm,-3,3,add = TRUE)

# Графический – график квантилей
qqnorm(x)
qqline(x)
grid()

# Шапиро-Уилка
# p-значение > 5%, распределение нормальное 
shapiro.test(x)

library(nortest)
# Критерий Лиллифорса
# p-значение > 5%, распределение нормальное
lillie.test(x)

# Критерий Андерсона-Дарлинга
# p-значение > 5%, распределение нормальное
ad.test(x)

```

## Связь нормального распределения и распределения Стьюдента

Распределения Стьюдента, специальное распределение для проверки статистических гипотез, когда мы имеем дело с небольшими выборками. При большом количестве степеней свободы (т.е. большом количестве наблюдений в выборке), разница между нормальным и распределением Стьюдента будет исчезать.

```{r}
# нарисуем плотность нормального распределения
curve(dnorm,-6,6)
# нарисуем плотность t-распределения c 3 степенями свободы
curve(dt(x,df = 3),-6,6,add = TRUE,col='red')
# нарисуем плотность t-распределения c 50 степенями свободы
curve(dt(x,df = 50),-6,6,add = TRUE,col='blue')
```

## Сравнение выборок

Для сравнения равенства среднего выборки с константой (одновыборочный t-критерий) вычисляется статистика, которая после этого сравнивают с критическим значением из распределения Стьюдента:

$t={\frac {{\overline {X}}-m}{s_{X}/{\sqrt {n}}}}$

Для сравнения средних 2 выборок вычисляется статистика, которая после этого сравнивается с критическим значением из распределения Стьюдента:

${\displaystyle t={\frac {{\overline {X}}_{1}-{\overline {X}}_{2}}{\sqrt {{\frac {s_{1}^{2}}{n_{1}}}+{\frac {s_{2}^{2}}{n_{2}}}}}}.}$

Для автоматизации всех этих вычислений в R есть функция t.test, позволяющая сократить необходимые вычисления для провередения t-теста Стьюдента.

```{r}
# здесь мы исходно используем данные из нормального распределения, поэтому не нужно проверять данные на нормальность
x = rnorm(100)
y = rnorm(100)

# можно сравнивать с числом
t.test(x,mu=0)

# сравним 2 выборки
t.test(x,y)
```

## Автомобильная задача

Рассмотрим на примере данных mtcars

```{r}
# t-stat
data("mtcars")
mtcars

# проверяем на нормальность данные - здесь получается что выборка у нас не нормальная. не можем использовать  t-test
shapiro.test(mtcars$hp)

#проверим на подвыборке машин с 4 цилиндрами - имеет нормальное распределение
shapiro.test(mtcars[mtcars$cyl==4,]$hp)

# можно ли сказать, что мощность автомобилей с 4 цилиндрами равна 80 л.с.? -  да можно, p-значение > 0.05
t.test(mtcars[mtcars$cyl==4,]$hp, mu = 80)

# можно использовать вычисления и вручную согласно формуле Стьюдента, но это долго)
(mean(subset(mtcars,cyl==4)$hp-80))/(sd(subset(mtcars,cyl==4)$hp)/sqrt(length(subset(mtcars,cyl==4)$hp)))
pt(0.417675, df = length(subset(mtcars,cyl==4)$hp))
p_value = 2*(1-pt(0.417675, df = length(subset(mtcars,cyl==4)$hp)))
# совпадает с результатом из t.test
p_value
```

### Расход топлива и количество передач

Проверим на нормальность расход топлива (mpg переменная) в 2 подвыборках авто - с 4 передачами и с 5-ю. После этого проведем t-тест.

```{r}
# имеет нормальное распределение
shapiro.test(mtcars[mtcars$gear==4,]$mpg)
# имеет нормальное распределение
shapiro.test(mtcars[mtcars$gear==5,]$mpg)

# проверим t-тестом, разницы в расходе топлива нет - т.к. p значение больше 5%
t.test(mtcars[mtcars$gear==4,]$mpg,mtcars[mtcars$gear==5,]$mpg)

```

### Мощность двигателя и тип двигателя

Проверим на нормальность количество лошадинных сил у 2 подвыборок авто - с обычными двигателем и v-образным.

```{r}
# выборка имеет нормальное распределение
shapiro.test(mtcars[mtcars$vs==0,]$hp)
# выборка имеет нормальное распределение
shapiro.test(mtcars[mtcars$vs==1,]$hp)
# t-тест можно вызывать еще и таким способ. Разница в количестве лошадинных сил в зависимости от типа двигателя есть - т.к. p значение меньше 5%
t.test(mtcars$hp~mtcars$vs)
```

## Дисперсионный анализ (ANOVA - analysis of variance)

С помощью однофакторного дисперсионного анализа можно сравнить средние значения зависимой переменной для двух и более групп, заданных группирующей переменной.

```{r}
#Проверим, влияет ли количество цилиндров на мощность автомобиля
anova <- aov(hp ~ cyl, data = mtcars)
summary(anova)


#Проверим, влияет ли количество передач на мощность автомобиля
anova <- aov(hp ~ gear, data = mtcars)
summary(anova)

```

С помощью двухфакторного дисперсионного анализа можно проверить влияние двух факторов на зависимую переменную. Продолжим работать с данными про автомобили

```{r}
#Проверим, влияет ли количество цилиндров и количество передач на мощность автомобиля

anova <- aov(hp ~ gear+cyl, data = mtcars)
summary(anova)
```
